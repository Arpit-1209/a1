{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79de05a-f466-464a-a112-e9ed42749faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans1)\n",
    "import random\n",
    "\n",
    "int_list = [random.randint(90, 130) for _ in range(100)]\n",
    "print(int_list)\n",
    "\n",
    "def calculate_mean(numbers):\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "mean_value = calculate_mean(int_list)\n",
    "print(\"Mean:\", mean_value)\n",
    "\n",
    "def calculate_median(numbers):\n",
    "    numbers.sort()\n",
    "    n = len(numbers)\n",
    "    if n % 2 == 0:\n",
    "        median = (numbers[n//2 - 1] + numbers[n//2]) / 2\n",
    "    else:\n",
    "        median = numbers[n//2]\n",
    "    return median\n",
    "\n",
    "median_value = calculate_median(int_list)\n",
    "print(\"Median:\", median_value)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_mode(numbers):\n",
    "    counter = Counter(numbers)\n",
    "    max_count = max(counter.values())\n",
    "    mode = [num for num, count in counter.items() if count == max_count]\n",
    "    return mode\n",
    "\n",
    "mode_value = calculate_mode(int_list)\n",
    "print(\"Mode:\", mode_value)\n",
    "\n",
    "def weighted_mean(values, weights):\n",
    "    return sum(v * w for v, w in zip(values, weights)) / sum(weights)\n",
    "\n",
    "values = int_list\n",
    "weights = [random.randint(1, 10) for _ in range(100)]\n",
    "w_mean_value = weighted_mean(values, weights)\n",
    "print(\"Weighted Mean:\", w_mean_value)\n",
    "\n",
    "import math\n",
    "\n",
    "def geometric_mean(numbers):\n",
    "    product = 1\n",
    "    for num in numbers:\n",
    "        product *= num\n",
    "    return product ** (1/len(numbers))\n",
    "\n",
    "geom_mean_value = geometric_mean([x for x in int_list if x > 0])\n",
    "print(\"Geometric Mean:\", geom_mean_value)\n",
    "\n",
    "def harmonic_mean(numbers):\n",
    "    return len(numbers) / sum(1/x for x in numbers if x != 0)\n",
    "\n",
    "harm_mean_value = harmonic_mean(int_list)\n",
    "print(\"Harmonic Mean:\", harm_mean_value)\n",
    "\n",
    "def midrange(numbers):\n",
    "    return (min(numbers) + max(numbers)) / 2\n",
    "\n",
    "midrange_value = midrange(int_list)\n",
    "print(\"Midrange:\", midrange_value)\n",
    "\n",
    "def trimmed_mean(numbers, percentage):\n",
    "    numbers.sort()\n",
    "    n = len(numbers)\n",
    "    trim = int(n * percentage)\n",
    "    trimmed_list = numbers[trim:-trim]\n",
    "    return sum(trimmed_list) / len(trimmed_list)\n",
    "\n",
    "trim_mean_value = trimmed_mean(int_list, 0.1)\n",
    "print(\"Trimmed Mean:\", trim_mean_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ac010-f0e6-43b2-a8ad-33c3593753ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans2)\n",
    "import random, math\n",
    "int_list2 = [random.randint(200, 300) for _ in range(500)]\n",
    "print(int_list2)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Frequency & Gaussian distribution\n",
    "sns.histplot(int_list2, kde=False, stat=\"density\")\n",
    "sns.kdeplot(int_list2)\n",
    "plt.title(\"Frequency & Gaussian Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Frequency smoothened KDE plot\n",
    "sns.histplot(int_list2, kde=True, stat=\"density\")\n",
    "plt.title(\"Frequency Smoothened KDE Plot\")\n",
    "plt.show()\n",
    "\n",
    "# Gaussian distribution & smoothened KDE plot\n",
    "sns.kdeplot(int_list2)\n",
    "sns.kdeplot(np.random.normal(np.mean(int_list2), np.std(int_list2), 1000), linestyle=\"--\")\n",
    "plt.title(\"Gaussian Distribution & Smoothened KDE Plot\")\n",
    "plt.show()\n",
    "\n",
    "def calculate_mean(numbers):\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "def calculate_range(numbers):\n",
    "    return max(numbers) - min(numbers)\n",
    "\n",
    "range_value = calculate_range(int_list2)\n",
    "print(\"Range:\", range_value)\n",
    "\n",
    "def calculate_variance(numbers):\n",
    "    mean = calculate_mean(numbers)\n",
    "    return sum((x - mean) ** 2 for x in numbers) / len(numbers)\n",
    "\n",
    "def calculate_std_dev(numbers):\n",
    "    variance = calculate_variance(numbers)\n",
    "    return math.sqrt(variance)\n",
    "\n",
    "variance_value = calculate_variance(int_list2)\n",
    "std_dev_value = calculate_std_dev(int_list2)\n",
    "print(\"Variance:\", variance_value)\n",
    "print(\"Standard Deviation:\", std_dev_value)\n",
    "\n",
    "def calculate_iqr(numbers):\n",
    "    numbers.sort()\n",
    "    q1 = np.percentile(numbers, 25)\n",
    "    q3 = np.percentile(numbers, 75)\n",
    "    return q3 - q1\n",
    "\n",
    "iqr_value = calculate_iqr(int_list2)\n",
    "print(\"Interquartile Range (IQR):\", iqr_value)\n",
    "\n",
    "def coefficient_of_variation(numbers):\n",
    "    return (calculate_std_dev(numbers) / calculate_mean(numbers)) * 100\n",
    "\n",
    "cv_value = coefficient_of_variation(int_list2)\n",
    "print(\"Coefficient of Variation:\", cv_value)\n",
    "\n",
    "def mean_absolute_deviation(numbers):\n",
    "    mean = calculate_mean(numbers)\n",
    "    return sum(abs(x - mean) for x in numbers) / len(numbers)\n",
    "\n",
    "mad_value = mean_absolute_deviation(int_list2)\n",
    "print(\"Mean Absolute Deviation (MAD):\", mad_value)\n",
    "\n",
    "def quartile_deviation(numbers):\n",
    "    numbers.sort()\n",
    "    q1 = np.percentile(numbers, 25)\n",
    "    q3 = np.percentile(numbers, 75)\n",
    "    return (q3 - q1) / 2\n",
    "\n",
    "qd_value = quartile_deviation(int_list2)\n",
    "print(\"Quartile Deviation:\", qd_value)\n",
    "\n",
    "def range_based_coefficient_of_dispersion(numbers):\n",
    "    return (calculate_range(numbers) / (max(numbers) + min(numbers))) * 100\n",
    "\n",
    "rbcd_value = range_based_coefficient_of_dispersion(int_list2)\n",
    "print(\"Range-Based Coefficient of Dispersion:\", rbcd_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee5faac-763c-4886-8868-c3afec741abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans3)\n",
    "class DiscreteRandomVariable:\n",
    "    def __init__(self, outcomes, probabilities):\n",
    "        self.outcomes = outcomes\n",
    "        self.probabilities = probabilities\n",
    "\n",
    "    def expected_value(self):\n",
    "        return sum(p * x for p, x in zip(self.probabilities, self.outcomes))\n",
    "\n",
    "    def variance(self):\n",
    "        mean = self.expected_value()\n",
    "        return sum(p * (x - mean) ** 2 for p, x in zip(self.probabilities, self.outcomes))\n",
    "\n",
    "outcomes = [1, 2, 3, 4, 5, 6]\n",
    "probabilities = [1/6] * 6\n",
    "\n",
    "drv = DiscreteRandomVariable(outcomes, probabilities)\n",
    "print(\"Expected Value:\", drv.expected_value())\n",
    "print(\"Variance:\", drv.variance())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c647f1e-a380-4a7a-9897-eaee7bf157f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans4)\n",
    "import random\n",
    "\n",
    "\n",
    "def simulate_dice_rolls(n):\n",
    "    rolls = [random.randint(1, 6) for _ in range(n)]\n",
    "    mean = calculate_mean(rolls)\n",
    "    variance = calculate_variance(rolls)\n",
    "    return mean, variance\n",
    "\n",
    "mean_roll, var_roll = simulate_dice_rolls(1000)\n",
    "print(\"Expected Value (Mean):\", mean_roll)\n",
    "print(\"Variance:\", var_roll)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec7404-b309-40aa-b57a-f148ee684cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans5)\n",
    "import numpy as np\n",
    "\n",
    "def generate_random_samples(dist, size, **kwargs):\n",
    "    if dist == \"binomial\":\n",
    "        samples = np.random.binomial(kwargs[\"n\"], kwargs[\"p\"], size)\n",
    "    elif dist == \"poisson\":\n",
    "        samples = np.random.poisson(kwargs[\"lam\"], size)\n",
    "    mean = calculate_mean(samples)\n",
    "    variance = calculate_variance(samples)\n",
    "    return samples, mean, variance\n",
    "\n",
    "samples, mean_binom, var_binom = generate_random_samples(\"binomial\", 1000, n=10, p=0.5)\n",
    "print(\"Binomial Distribution - Mean:\", mean_binom, \"Variance:\", var_binom)\n",
    "\n",
    "samples, mean_poisson, var_poisson = generate_random_samples(\"poisson\", 1000, lam=4)\n",
    "print(\"Poisson Distribution - Mean:\", mean_poisson, \"Variance:\", var_poisson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f954e-a8b6-44e3-af9a-48a981462140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans6)\n",
    "import numpy as np\n",
    "\n",
    "def gaussian_distribution(mean, std_dev, size):\n",
    "    samples = np.random.normal(mean, std_dev, size)\n",
    "    mean_value = calculate_mean(samples)\n",
    "    variance_value = calculate_variance(samples)\n",
    "    std_dev_value = calculate_std_dev(samples)\n",
    "    return samples, mean_value, variance_value, std_dev_value\n",
    "\n",
    "samples, mean_gauss, var_gauss, std_gauss = gaussian_distribution(0, 1, 1000)\n",
    "print(\"Gaussian Distribution - Mean:\", mean_gauss, \"Variance:\", var_gauss, \"Standard Deviation:\", std_gauss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9309a-c2be-45a8-b36a-df1a1be6fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans7)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, pearsonr\n",
    "\n",
    "# Load the tips dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(tips.head())\n",
    "\n",
    "# Function to calculate skewness\n",
    "def calculate_skewness(data):\n",
    "    return skew(data)\n",
    "\n",
    "# Calculate skewness for 'total_bill' and 'tip'\n",
    "skew_total_bill = calculate_skewness(tips['total_bill'])\n",
    "skew_tip = calculate_skewness(tips['tip'])\n",
    "\n",
    "print(f\"Skewness of 'total_bill': {skew_total_bill}\")\n",
    "print(f\"Skewness of 'tip': {skew_tip}\")\n",
    "\n",
    "# Determine skewness type\n",
    "def skewness_type(skew_value):\n",
    "    if skew_value > 0:\n",
    "        return \"Positive skewness\"\n",
    "    elif skew_value < 0:\n",
    "        return \"Negative skewness\"\n",
    "    else:\n",
    "        return \"Approximately symmetric\"\n",
    "\n",
    "print(f\"Skewness type of 'total_bill': {skewness_type(skew_total_bill)}\")\n",
    "print(f\"Skewness type of 'tip': {skewness_type(skew_tip)}\")\n",
    "\n",
    "# Function to calculate covariance between two columns\n",
    "def calculate_covariance(data, col1, col2):\n",
    "    return data[col1].cov(data[col2])\n",
    "\n",
    "covariance_total_bill_tip = calculate_covariance(tips, 'total_bill', 'tip')\n",
    "print(f\"Covariance between 'total_bill' and 'tip': {covariance_total_bill_tip}\")\n",
    "\n",
    "# Function to calculate Pearson correlation coefficient\n",
    "def calculate_correlation(data, col1, col2):\n",
    "    return data[col1].corr(data[col2])\n",
    "\n",
    "correlation_total_bill_tip = calculate_correlation(tips, 'total_bill', 'tip')\n",
    "print(f\"Pearson correlation coefficient between 'total_bill' and 'tip': {correlation_total_bill_tip}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot to visualize correlation\n",
    "def visualize_correlation(data, col1, col2):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=col1, y=col2, data=data)\n",
    "    plt.title(f'Scatter plot of {col1} vs {col2}')\n",
    "    plt.xlabel(col1)\n",
    "    plt.ylabel(col2)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize correlation between 'total_bill' and 'tip'\n",
    "visualize_correlation(tips, 'total_bill', 'tip')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32f7709-1726-4f22-a3bf-4dbd4c179a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans8)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "def calculate_normal_pdf(x, mean, std_dev):\n",
    "    pdf_values = norm.pdf(x, loc=mean, scale=std_dev)\n",
    "    return pdf_values\n",
    "\n",
    "# Example usage:\n",
    "mean = 0   # Mean of the normal distribution\n",
    "std_dev = 1   # Standard deviation of the normal distribution\n",
    "\n",
    "# Generate x values for which to calculate the PDF\n",
    "x_values = np.linspace(-5, 5, 100)\n",
    "pdf_values = calculate_normal_pdf(x_values, mean, std_dev)\n",
    "\n",
    "# Plotting the PDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_values, pdf_values, label=f'Normal PDF (μ={mean}, σ={std_dev})')\n",
    "plt.title('Probability Density Function (PDF) of Normal Distribution')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('PDF(x)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009b901-8c5a-47d1-84bf-1dd529dc8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans9)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon\n",
    "\n",
    "def calculate_exponential_cdf(x, scale):\n",
    "   \n",
    "    cdf_values = expon.cdf(x, scale=scale)\n",
    "    return cdf_values\n",
    "\n",
    "# Example usage:\n",
    "scale = 1   # Scale parameter (β) of the exponential distribution\n",
    "\n",
    "# Generate x values for which to calculate the CDF\n",
    "x_values = np.linspace(0, 5, 100)\n",
    "cdf_values = calculate_exponential_cdf(x_values, scale)\n",
    "\n",
    "# Plotting the CDF\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_values, cdf_values, label=f'Exponential CDF (β={scale})')\n",
    "plt.title('Cumulative Distribution Function (CDF) of Exponential Distribution')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('CDF(x)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c667c97-1276-4c50-b694-296b874e2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans10)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "\n",
    "def calculate_poisson_pmf(k, mu):\n",
    "    \"\"\"\n",
    "    Calculate the Probability Mass Function (PMF) of a Poisson distribution.\n",
    "\n",
    "    Parameters:\n",
    "    - k: The point(s) at which to calculate the PMF (can be a scalar or an array-like).\n",
    "    - mu: The mean (λ) of the Poisson distribution.\n",
    "\n",
    "    Returns:\n",
    "    - pmf_values: The PMF value(s) at point(s) k.\n",
    "    \"\"\"\n",
    "    pmf_values = poisson.pmf(k, mu)\n",
    "    return pmf_values\n",
    "\n",
    "# Example usage:\n",
    "mu = 3   # Mean (λ) of the Poisson distribution\n",
    "\n",
    "# Generate k values for which to calculate the PMF\n",
    "k_values = np.arange(0, 10)\n",
    "pmf_values = calculate_poisson_pmf(k_values, mu)\n",
    "\n",
    "# Plotting the PMF\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.stem(k_values, pmf_values, linefmt='b-', markerfmt='bo', basefmt=' ', label=f'Poisson PMF (λ={mu})')\n",
    "plt.title('Probability Mass Function (PMF) of Poisson Distribution')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('PMF(k)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9661178-68fa-4271-be1d-48a63dab829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans11)\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# Define the data\n",
    "old_purchases = 50\n",
    "old_visitors = 1000\n",
    "old_layout = np.array([1] * old_purchases + [0] * (old_visitors - old_purchases))\n",
    "\n",
    "new_purchases = 70\n",
    "new_visitors = 1000\n",
    "new_layout = np.array([1] * new_purchases + [0] * (new_visitors - new_purchases))\n",
    "\n",
    "# Perform z-test for proportions\n",
    "count = np.array([old_purchases, new_purchases])\n",
    "nobs = np.array([old_visitors, new_visitors])\n",
    "\n",
    "stat, pval = proportions_ztest(count, nobs, alternative='larger')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Z-test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {pval:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if pval < alpha:\n",
    "    print(\"Reject the null hypothesis: The new layout leads to a significantly higher conversion rate.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in conversion rates between the layouts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96982bf4-72b3-4156-851d-3bd6cc3f5cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans12)\n",
    "import numpy as np\n",
    "from statsmodels.stats import weightstats as stests\n",
    "\n",
    "# Define the data\n",
    "before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
    "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
    "\n",
    "# Perform paired z-test for means\n",
    "stat, pval = stests.ztest(before_program, after_program)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Z-test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {pval:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if pval < alpha:\n",
    "    print(\"Reject the null hypothesis: The tutoring program significantly improves exam scores.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant improvement in exam scores from the tutoring program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e70a7a-f73f-4f98-bdca-164581b8683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans13)\n",
    "import numpy as np\n",
    "from statsmodels.stats import weightstats as stests\n",
    "\n",
    "# Define the data\n",
    "before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
    "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
    "\n",
    "# Perform paired z-test for means\n",
    "stat, pval = stests.ztest(before_program, after_program)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Z-test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {pval:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if pval < alpha:\n",
    "    print(\"Reject the null hypothesis: The tutoring program significantly improves exam scores.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant improvement in exam scores from the tutoring program.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ecb6b5-fdb2-491f-bdfa-21819a0e5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans14)\n",
    "import numpy as np\n",
    "from statsmodels.stats import weightstats as stests\n",
    "\n",
    "# Define the data\n",
    "response_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.41])\n",
    "\n",
    "# Population mean under the null hypothesis\n",
    "pop_mean = 5\n",
    "\n",
    "# Perform one-sample z-test for mean\n",
    "stat, pval = stests.ztest(response_times, value=pop_mean, alternative='smaller')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Z-test statistic: {stat:.4f}\")\n",
    "print(f\"P-value: {pval:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if pval < alpha:\n",
    "    print(\"Reject the null hypothesis: The average response time is less than 5 minutes.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no sufficient evidence that the average response time is less than 5 minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f0e59-e116-4a22-a3f1-3ede78257022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans15)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def ab_test(layout_a_clicks, layout_b_clicks):\n",
    "    # Calculate sample statistics\n",
    "    mean_a = np.mean(layout_a_clicks)\n",
    "    mean_b = np.mean(layout_b_clicks)\n",
    "    var_a = np.var(layout_a_clicks, ddof=1)\n",
    "    var_b = np.var(layout_b_clicks, ddof=1)\n",
    "    n_a = len(layout_a_clicks)\n",
    "    n_b = len(layout_b_clicks)\n",
    "    \n",
    "    # Calculate pooled standard deviation\n",
    "    pooled_std = np.sqrt((var_a/n_a) + (var_b/n_b))\n",
    "    \n",
    "    # Calculate t-statistic\n",
    "    t_statistic = (mean_a - mean_b) / pooled_std\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    dof = n_a + n_b - 2\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_statistic), dof))\n",
    "    \n",
    "    return t_statistic, dof, p_value\n",
    "\n",
    "# Define the data\n",
    "layout_a_clicks = np.array([28, 32, 33, 29, 31, 34, 30, 35, 36, 37])\n",
    "layout_b_clicks = np.array([40, 41, 38, 42, 39, 44, 43, 41, 45, 47])\n",
    "\n",
    "# Perform A/B test analysis\n",
    "t_statistic, dof, p_value = ab_test(layout_a_clicks, layout_b_clicks)\n",
    "\n",
    "# Print the results\n",
    "print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in click-through rates between the two layouts.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in click-through rates between the two layouts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505f863-3d38-45e8-bd50-a6c9e7878b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans16)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def independent_t_test(data1, data2):\n",
    "    # Calculate sample statistics\n",
    "    mean1 = np.mean(data1)\n",
    "    mean2 = np.mean(data2)\n",
    "    var1 = np.var(data1, ddof=1)\n",
    "    var2 = np.var(data2, ddof=1)\n",
    "    n1 = len(data1)\n",
    "    n2 = len(data2)\n",
    "    \n",
    "    # Calculate pooled standard deviation\n",
    "    pooled_std = np.sqrt((var1/n1) + (var2/n2))\n",
    "    \n",
    "    # Calculate t-statistic\n",
    "    t_statistic = (mean1 - mean2) / pooled_std\n",
    "    \n",
    "    # Degrees of freedom (approximated using Welch's formula)\n",
    "    dof = ((var1/n1 + var2/n2)**2) / ((var1**2 / (n1**2 * (n1 - 1))) + (var2**2 / (n2**2 * (n2 - 1))))\n",
    "    \n",
    "    # Calculate p-value\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_statistic), dof))\n",
    "    \n",
    "    return t_statistic, dof, p_value\n",
    "\n",
    "# Define the data\n",
    "existing_drug_levels = np.array([180, 182, 175, 185, 178, 176, 172, 184, 179, 183])\n",
    "new_drug_levels = np.array([170, 172, 165, 168, 175, 173, 170, 178, 172, 176])\n",
    "\n",
    "# Perform two-sample independent t-test\n",
    "t_statistic, dof, p_value = independent_t_test(existing_drug_levels, new_drug_levels)\n",
    "\n",
    "# Print the results\n",
    "print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The new drug is more effective than the existing drug in reducing cholesterol levels.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no sufficient evidence that the new drug is more effective than the existing drug.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81948515-027f-4e08-9e01-b876fb2ff832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans17)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def paired_t_test(pre_scores, post_scores):\n",
    "    # Perform paired sample t-test\n",
    "    t_statistic, p_value = stats.ttest_rel(post_scores, pre_scores)\n",
    "    \n",
    "    return t_statistic, p_value\n",
    "\n",
    "# Define the data\n",
    "pre_intervention_scores = np.array([80, 85, 90, 75, 88, 82, 92, 78, 85, 87])\n",
    "post_intervention_scores = np.array([90, 88, 92, 95, 91, 96, 93, 89, 93])\n",
    "\n",
    "# Perform paired sample t-test\n",
    "t_statistic, p_value = paired_t_test(pre_intervention_scores, post_intervention_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The intervention had a significant impact on math scores.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no sufficient evidence that the intervention had a significant impact on math scores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e42f6-4988-49ef-a531-f7cca6db2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans18)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate synthetic salary data for male and female employees\n",
    "np.random.seed(0)  # For reproducibility\n",
    "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
    "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)\n",
    "\n",
    "def independent_t_test(data1, data2):\n",
    "    # Perform two-sample independent t-test\n",
    "    t_statistic, p_value = stats.ttest_ind(data1, data2, equal_var=False)\n",
    "    \n",
    "    return t_statistic, p_value\n",
    "\n",
    "# Perform two-sample independent t-test on the synthetic data\n",
    "t_statistic, p_value = independent_t_test(male_salaries, female_salaries)\n",
    "\n",
    "# Print the results\n",
    "print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a statistically significant difference in average salaries between male and female employees.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no statistically significant difference in average salaries between male and female employees.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a520d-0e59-48fd-94a8-479c47060fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans19)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Define the data\n",
    "version1_scores = np.array([85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85])\n",
    "version2_scores = np.array([80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82])\n",
    "\n",
    "def independent_t_test(data1, data2):\n",
    "    # Perform two-sample independent t-test\n",
    "    t_statistic, p_value = stats.ttest_ind(data1, data2, equal_var=False)\n",
    "    \n",
    "    return t_statistic, p_value\n",
    "\n",
    "# Perform two-sample independent t-test on the given data\n",
    "t_statistic, p_value = independent_t_test(version1_scores, version2_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a statistically significant difference in quality scores between the two versions.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no statistically significant difference in quality scores between the two versions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a17f6-3020-42b5-9b6e-2d09efdaae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans20)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Define the data\n",
    "branch_a_scores = np.array([4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4])\n",
    "branch_b_scores = np.array([3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3])\n",
    "\n",
    "def independent_t_test(data1, data2):\n",
    "    # Perform two-sample independent t-test\n",
    "    t_statistic, p_value = stats.ttest_ind(data1, data2, equal_var=False)\n",
    "    \n",
    "    return t_statistic, p_value\n",
    "\n",
    "# Perform two-sample independent t-test on the given data\n",
    "t_statistic, p_value = independent_t_test(branch_a_scores, branch_b_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"t-statistic: {t_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a statistically significant difference in customer satisfaction between the two branches.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no statistically significant difference in customer satisfaction between the two branches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379dbaa5-1f0f-435b-a378-1f18f8aa5b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans21)\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "age_groups = np.random.choice(['18-30', '31-50', '51+'], size=500)\n",
    "voter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=500)\n",
    "\n",
    "# Create a contingency table (observed frequencies)\n",
    "contingency_table = np.zeros((3, 2), dtype=int)\n",
    "\n",
    "for i, age_group in enumerate(['18-30', '31-50', '51+']):\n",
    "    for j, preference in enumerate(['Candidate A', 'Candidate B']):\n",
    "        contingency_table[i, j] = np.sum((age_groups == age_group) & (voter_preferences == preference))\n",
    "\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Perform Chi-Square test for independence\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nChi-Square Statistic: {chi2:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: There is a significant association between age groups and voter preferences.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant association between age groups and voter preferences.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc9105-fff9-448e-b8e9-70cdaf6a947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans22)\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Define the contingency table (observed frequencies)\n",
    "data = np.array([[50, 30, 40, 20],\n",
    "                 [30, 40, 30, 50],\n",
    "                 [20, 30, 40, 30]])\n",
    "\n",
    "# Perform Chi-Square test for independence\n",
    "chi2, p_value, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-Square Statistic: {chi2:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: There is a significant relationship between product satisfaction levels and customer regions.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant relationship between product satisfaction levels and customer regions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5ae47-82d0-4206-872c-07cfb9c2dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans23)\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Define the contingency table (observed frequencies)\n",
    "data = np.array([[50, 30, 20],\n",
    "                 [30, 40, 30],\n",
    "                 [20, 30, 40]])\n",
    "\n",
    "# Perform Chi-Square test for independence\n",
    "chi2, p_value, dof, expected = chi2_contingency(data)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-Square Statistic: {chi2:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: There is a significant difference between job performance levels before and after the training.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant difference between job performance levels before and after the training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25286b15-a30f-4dd4-8687-63b2200dc35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Ans24)\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Define the data\n",
    "standard_scores = np.array([80, 85, 90, 78, 88, 82, 92, 78, 85, 87])\n",
    "premium_scores = np.array([90, 92, 88, 92, 95, 91, 96, 93, 89, 93])\n",
    "deluxe_scores = np.array([95, 98, 92, 97, 96, 94, 98, 97, 92, 99])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(standard_scores, premium_scores, deluxe_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"One-way ANOVA\")\n",
    "print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis: There is a significant difference in customer satisfaction scores among the three product versions.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis: There is no significant difference in customer satisfaction scores among the three product versions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495a8dc-f236-4fa9-a347-77859705d76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38236675-668d-4c94-8a99-890a235acc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9202c-dcec-43b7-897c-fbee6d15a244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045567a8-ba3b-462d-9fb1-92697cc8d19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fd3ec-fd77-46a6-8f2a-e8d02e206906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8597181-e1ad-47f8-8c3c-98c44ce91c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf52f0f-42d0-434a-95c0-4e3640c92765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99efda43-3beb-4b41-b7c3-5e58c731c6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03909ba6-7119-4115-bb28-d946515c8d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b12b4-5884-4842-a304-55ee3d1ce420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a45b9a-1742-48ad-ac42-07f7eab35403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
